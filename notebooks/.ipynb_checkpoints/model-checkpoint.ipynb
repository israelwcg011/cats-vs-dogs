{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40fd1439-6c8e-4e71-b30c-ee88a4b4a035",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e76f5807-d158-4f01-8cc5-3f03a30a246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import PIL\n",
    "from contextlib import redirect_stdout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b58cf4-1264-4618-aeff-462b1d263ff1",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41671824-8980-4360-a49d-2ed6cb8baa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "img_width = 120\n",
    "img_height = 120\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb18cd4c-1d0c-4a9f-8fc3-583aa3988544",
   "metadata": {},
   "source": [
    "# Preprocess data to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99e92a8-b032-44d1-9a38-ad560c335eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "data = pd.read_csv(\"../datasets/train.csv\")\n",
    "\n",
    "# replace labels {0: \"cat\", 1: \"dog\"}\n",
    "data[\"label\"] = data[\"label\"].replace({0: \"cat\", 1: \"dog\"})\n",
    "\n",
    "# train validation split\n",
    "df_train, df_validation = train_test_split(data, test_size=0.15, random_state=2)\n",
    "\n",
    "# reset train and validation dataframes indexes\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_validation = df_validation.reset_index(drop=True)\n",
    "\n",
    "# get some metadada from train and validation dataframes\n",
    "df_train_shape = df_train.shape\n",
    "df_validation_shape = df_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82cffbc3-3d05-4b85-9721-a4ddc510c45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image address</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/train\\cat.10290.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/train\\dog.4021.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     image address label\n",
       "0  ../datasets/train\\cat.10290.jpg   cat\n",
       "1   ../datasets/train\\dog.4021.jpg   dog"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef3453-bb54-4725-ac5d-be7b21b387a6",
   "metadata": {},
   "source": [
    "# Train and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced27e5-cc65-4dde-b602-285ca6428a24",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c314193a-d500-464f-97fe-2e08e02c3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e11a1ac-4eb1-4cbc-a212-6d7a49b2a6d9",
   "metadata": {},
   "source": [
    "### Build data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733ffd5c-14b2-4a67-889f-b6679e60bd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21250 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    df_train,\n",
    "    x_col=\"image address\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86a1db5-288c-42a0-9ee5-dab3ac15d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3750 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_data_generator.flow_from_dataframe(\n",
    "    df_validation,\n",
    "    x_col=\"image address\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824453e8-5f7f-4a40-b9a8-e6afb373e10c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298af813-b92d-4a7e-b419-fe477feb2210",
   "metadata": {},
   "source": [
    "### Create model archtecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86374680-aa38-4783-b38f-84c6a676d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation=\"relu\", input_shape=(img_width, img_height, img_channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (4,4), activation=\"relu\", input_shape=(img_width, img_height, img_channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128939fb-c330-45c9-a6b0-2f0ed9bf20e8",
   "metadata": {},
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e610a30d-53d1-4c81-b2c8-ac1bf012ce18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 118, 118, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 118, 118, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 59, 59, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 59, 59, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 56, 56, 128)       65664     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 56, 56, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 28, 28, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               12845184  \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,913,154\n",
      "Trainable params: 12,912,578\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97a3f3-c4a6-4b8f-8379-a57624ae7e2e",
   "metadata": {},
   "source": [
    "### Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1090d76-d60c-414a-a0a0-01ad07cbc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience = 5)\n",
    "callbacks = [earlystop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e7837-3e27-4b34-8612-1b3edfac0f71",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91cc0a38-5101-4ad2-83b4-7e920e9375f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2125/2125 [==============================] - 634s 298ms/step - loss: 0.6406 - accuracy: 0.6587 - val_loss: 0.6290 - val_accuracy: 0.6547\n",
      "Epoch 2/10\n",
      "2125/2125 [==============================] - 430s 202ms/step - loss: 0.5256 - accuracy: 0.7421 - val_loss: 0.5455 - val_accuracy: 0.7637\n",
      "Epoch 3/10\n",
      "2125/2125 [==============================] - 431s 203ms/step - loss: 0.4921 - accuracy: 0.7646 - val_loss: 0.5663 - val_accuracy: 0.7069\n",
      "Epoch 4/10\n",
      "2125/2125 [==============================] - 430s 203ms/step - loss: 0.4737 - accuracy: 0.7773 - val_loss: 0.4990 - val_accuracy: 0.7976\n",
      "Epoch 5/10\n",
      "2125/2125 [==============================] - 430s 202ms/step - loss: 0.4590 - accuracy: 0.7881 - val_loss: 0.4235 - val_accuracy: 0.8176\n",
      "Epoch 6/10\n",
      "2125/2125 [==============================] - 430s 203ms/step - loss: 0.4362 - accuracy: 0.8024 - val_loss: 0.6682 - val_accuracy: 0.7824\n",
      "Epoch 7/10\n",
      "2125/2125 [==============================] - 438s 206ms/step - loss: 0.4245 - accuracy: 0.8076 - val_loss: 0.3772 - val_accuracy: 0.8400\n",
      "Epoch 8/10\n",
      "2125/2125 [==============================] - 432s 203ms/step - loss: 0.4258 - accuracy: 0.8094 - val_loss: 0.4286 - val_accuracy: 0.8272\n",
      "Epoch 9/10\n",
      "2125/2125 [==============================] - 435s 205ms/step - loss: 0.4106 - accuracy: 0.8163 - val_loss: 0.7623 - val_accuracy: 0.6155\n",
      "Epoch 10/10\n",
      "2125/2125 [==============================] - 448s 211ms/step - loss: 0.4062 - accuracy: 0.8177 - val_loss: 0.4375 - val_accuracy: 0.8064\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=df_validation_shape[0]//batch_size,\n",
    "    steps_per_epoch=df_train_shape[0]//batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59514c-348e-433f-a894-ee05aecd486e",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b3a9b1c-826a-451e-9cee-49ca9b275561",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../backend/models/cats_vs_dogs_model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d9d31fe-4752-48d7-b8cf-143efec9cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../backend/models/cats_vs_dogs_model_1_summary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dogs-vs-cats",
   "language": "python",
   "name": "venv-dogs-vs-cats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
